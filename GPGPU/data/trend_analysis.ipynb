{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c24e302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Jaccard Similarity on Absolute Throughput (Per-App Thresholds) ===\n",
      "Group  App                  Threshold  Jaccard\n",
      "altis  bfs                  300        0.963\n",
      "altis  gemm                 500        0.909\n",
      "altis  pathfinder           300        0.955\n",
      "altis  sort                 500        0.995\n",
      "altis  cfd                  300        0.891\n",
      "altis  cfd_double           500        0.833\n",
      "altis  fdtd2d               3000       0.97\n",
      "altis  kmeans               500        0.882\n",
      "altis  lavamd               500        0.801\n",
      "altis  nw                   5000       0.877\n",
      "altis  particlefilter_float 40         0.684\n",
      "altis  raytracing           50         0.849\n",
      "altis  srad                 500        0.949\n",
      "altis  where                300        0.988\n",
      "ecp    Laghos               500        0.995\n",
      "ecp    miniGAN              500        0.922\n",
      "ecp    sw4lite              1000       0.864\n",
      "ecp    UNet                 500        0.931\n",
      "ecp    Resnet50             500        0.804\n",
      "ecp    bert_large           130        0.748\n",
      "ecp    lammps               5000       0.962\n",
      "ecp    gromacs              500        0.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import os\n",
    "\n",
    "# === Configuration ===\n",
    "colname = ' total(MB/s)'\n",
    "time_col = 'Time Elapsed (s)'\n",
    "\n",
    "# === ALTIS config ===\n",
    "altis_base = '/Users/zhongzheng/Desktop/power/GPGPU/data/altis_power_res/no_power_shift/mem_throughput'\n",
    "altis_benchmarks = [\n",
    "    \"bfs\", \"gemm\", \"pathfinder\", \"sort\", \"cfd\", \"cfd_double\", \"fdtd2d\",\n",
    "    \"kmeans\", \"lavamd\", \"nw\", \"particlefilter_float\", \"raytracing\",\"srad\", \"where\"\n",
    "]\n",
    "altis_ts = [300, 500, 300, 500, 300, 500, 3000, 500, 500, 5000, 40, 50, 500, 300]\n",
    "altis_threshold_map = dict(zip(altis_benchmarks, altis_ts))\n",
    "\n",
    "# === ECP config ===\n",
    "ecp_base = '/Users/zhongzheng/Desktop/power/GPGPU/data/ecp_power_res/no_power_shift/mem_throughput'\n",
    "ecp_benchmarks = [\n",
    "    'Laghos', 'miniGAN', 'sw4lite', 'UNet', 'Resnet50', 'bert_large', 'lammps', 'gromacs'\n",
    "]\n",
    "\n",
    "# ecp_benchmarks = []\n",
    "\n",
    "ecp_ts = [500, 500, 1000, 500, 500, 130, 5000, 500]\n",
    "ecp_threshold_map = dict(zip(ecp_benchmarks, ecp_ts))\n",
    "\n",
    "# === Combine all benchmarks and thresholds ===\n",
    "benchmark_sets = [\n",
    "    (\"altis\", altis_base, altis_benchmarks, altis_threshold_map),\n",
    "    (\"ecp\", ecp_base, ecp_benchmarks, ecp_threshold_map)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# === Core logic ===\n",
    "for label, base_dir, benchmarks, threshold_map in benchmark_sets:\n",
    "    for app in benchmarks:\n",
    "        try:\n",
    "            threshold = threshold_map[app]\n",
    "\n",
    "            # Load CSVs\n",
    "            path_max = os.path.join(base_dir, 'max_uncore', f'{app}.csv')\n",
    "            path_mag = os.path.join(base_dir, 'dynamic_uncore', f'{app}.csv')\n",
    "\n",
    "            df_max = pd.read_csv(path_max)\n",
    "            df_mag = pd.read_csv(path_mag)\n",
    "\n",
    "            # Filter by time for specific apps\n",
    "            if app == 'bert_large':\n",
    "                df_max = df_max[df_max[time_col] > 220]\n",
    "                df_mag = df_mag[df_mag[time_col] > 220]\n",
    "            elif app == 'Resnet50':\n",
    "                df_max = df_max[df_max[time_col] > 60]\n",
    "                df_mag = df_mag[df_mag[time_col] > 60]\n",
    "\n",
    "            # Parse throughput values\n",
    "            T_max = pd.to_numeric(df_max[colname].astype(str).str.strip(), errors='coerce').dropna().values\n",
    "            T_mag = pd.to_numeric(df_mag[colname].astype(str).str.strip(), errors='coerce').dropna().values\n",
    "\n",
    "            # Align lengths\n",
    "            min_len = min(len(T_max), len(T_mag))\n",
    "            T_max = T_max[:min_len]\n",
    "            T_mag = T_mag[:min_len]\n",
    "\n",
    "            # Burst masks based on absolute value threshold\n",
    "            burst_max = (T_max > threshold).astype(int)\n",
    "            burst_mag = (T_mag > threshold).astype(int)\n",
    "\n",
    "            # Compute Jaccard similarity\n",
    "            jaccard = jaccard_score(burst_max, burst_mag)\n",
    "            results.append((label, app, threshold, round(jaccard, 3)))\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append((label, app, \"N/A\", f\"ERROR: {e}\"))\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"\\n=== Jaccard Similarity on Absolute Throughput (Per-App Thresholds) ===\")\n",
    "print(f\"{'Group':<6} {'App':<20} {'Threshold':<10} {'Jaccard'}\")\n",
    "for group, app, thresh, score in results:\n",
    "    print(f\"{group:<6} {app:<20} {thresh:<10} {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "850dfe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Jaccard Burst Overlap Similarity (Adaptive Thresholds) ===\n",
      "Group  App                  Threshold  Jaccard\n",
      "altis  bfs                  0.995\n",
      "altis  gemm                 0.714\n",
      "altis  pathfinder           0.98\n",
      "altis  sort                 0.968\n",
      "altis  cfd                  0.947\n",
      "altis  cfd_double           0.631\n",
      "altis  fdtd2d               0.4\n",
      "altis  kmeans               0.977\n",
      "altis  lavamd               0.922\n",
      "altis  nw                   1.0\n",
      "altis  particlefilter_float 0.675\n",
      "altis  raytracing           0.87\n",
      "altis  where                0.946\n",
      "ecp    Laghos               0.995\n",
      "ecp    miniGAN              0.988\n",
      "ecp    sw4lite              0.872\n",
      "ecp    UNet                 0.99\n",
      "ecp    Resnet50             0.964\n",
      "ecp    bert_large           0.844\n",
      "ecp    lammps               0.995\n",
      "ecp    gromacs              0.993\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import os\n",
    "\n",
    "# === Configuration ===\n",
    "colname = ' total(MB/s)'        # Throughput column\n",
    "time_col = 'Time Elapsed (s)'   # Timestamp column\n",
    "\n",
    "# === Benchmark groups ===\n",
    "altis_base = '/Users/zhongzheng/Desktop/power/GPGPU/data/altis_power_res/no_power_shift/mem_throughput'\n",
    "altis_benchmarks = [\n",
    "    \"bfs\", \"gemm\", \"pathfinder\", \"sort\", \"cfd\", \"cfd_double\", \"fdtd2d\",\n",
    "    \"kmeans\", \"lavamd\", \"nw\", \"particlefilter_float\", \"raytracing\", \"where\"\n",
    "]\n",
    "\n",
    "ecp_base = '/Users/zhongzheng/Desktop/power/GPGPU/data/ecp_power_res/no_power_shift/mem_throughput'\n",
    "ecp_benchmarks = [\n",
    "    'Laghos', 'miniGAN', 'sw4lite', 'UNet', 'Resnet50', 'bert_large', 'lammps', 'gromacs'\n",
    "]\n",
    "\n",
    "benchmark_sets = [\n",
    "    (\"altis\", altis_base, altis_benchmarks),\n",
    "    (\"ecp\", ecp_base, ecp_benchmarks)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# === Core logic ===\n",
    "for label, base_dir, benchmarks in benchmark_sets:\n",
    "    for app in benchmarks:\n",
    "        try:\n",
    "            # Load CSVs\n",
    "            path_max = os.path.join(base_dir, 'max_uncore', f'{app}.csv')\n",
    "            path_mag = os.path.join(base_dir, 'dynamic_uncore', f'{app}.csv')\n",
    "\n",
    "            df_max = pd.read_csv(path_max)\n",
    "            df_mag = pd.read_csv(path_mag)\n",
    "\n",
    "            # Filter by time (optional per app)\n",
    "            if app == 'bert_large':\n",
    "                df_max = df_max[df_max[time_col].between(220, 300)]\n",
    "                df_mag = df_mag[df_mag[time_col].between(220, 300)]\n",
    "\n",
    "            elif app == 'Resnet50':\n",
    "                df_max = df_max[df_max[time_col] > 60]\n",
    "                df_mag = df_mag[df_mag[time_col] > 60]\n",
    "\n",
    "            # Clean and parse throughput column\n",
    "            T_max = pd.to_numeric(df_max[colname].astype(str).str.strip(), errors='coerce').dropna().values\n",
    "            T_mag = pd.to_numeric(df_mag[colname].astype(str).str.strip(), errors='coerce').dropna().values\n",
    "\n",
    "            # Align lengths\n",
    "            min_len = min(len(T_max), len(T_mag))\n",
    "            T_max = T_max[:min_len]\n",
    "            T_mag = T_mag[:min_len]\n",
    "\n",
    "            # === Adaptive threshold: 50% of max ==\n",
    "            \n",
    "\n",
    "            adaptive_threshold = min(T_mag.min() * 1.3, T_mag.max())\n",
    "            adaptive_threshold = T_mag.min() * 1.5\n",
    "            # Binary burst masks\n",
    "            burst_max = (T_max > adaptive_threshold).astype(int)\n",
    "            burst_mag = (T_mag > adaptive_threshold).astype(int)\n",
    "\n",
    "            # Jaccard score\n",
    "            jaccard = jaccard_score(burst_max, burst_mag)\n",
    "            results.append((label, app, round(adaptive_threshold, 1), round(jaccard, 3)))\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append((label, app, \"N/A\", f\"ERROR: {e}\"))\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"\\n=== Jaccard Burst Overlap Similarity (Adaptive Thresholds) ===\")\n",
    "print(f\"{'Group':<6} {'App':<20} {'Threshold':<10} {'Jaccard'}\")\n",
    "for group, app, thresh, score in results:\n",
    "    print(f\"{group:<6} {app:<20} {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09c31200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Jaccard Burst Overlap Similarity (Fuzzy ±1s Tolerance) ===\n",
      "Group  App                  Threshold  Jaccard\n",
      "altis  bfs                  9379.1     0.871\n",
      "altis  gemm                 2208.2     1.0\n",
      "altis  pathfinder           3113.3     0.952\n",
      "altis  sort                 4074.3     0.515\n",
      "altis  cfd                  4684.4     0.643\n",
      "altis  cfd_double           3930.6     0.5\n",
      "altis  fdtd2d               5571.1     0.5\n",
      "altis  kmeans               4455.9     0.333\n",
      "altis  lavamd               9398.5     0.083\n",
      "altis  nw                   3164.8     0.933\n",
      "altis  particlefilter_float 539.3      0.615\n",
      "altis  raytracing           167.4      0.133\n",
      "altis  where                5958.8     0.364\n",
      "ecp    Laghos               576.5      0.941\n",
      "ecp    miniGAN              20899.6    0.077\n",
      "ecp    sw4lite              6424.1     0.875\n",
      "ecp    UNet                 43410.3    0.176\n",
      "ecp    Resnet50             4740.6     0.642\n",
      "ecp    bert_large           284.8      0.09\n",
      "ecp    lammps               7215.1     0.964\n",
      "ecp    gromacs              3284.7     0.361\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import os\n",
    "\n",
    "# === Configuration ===\n",
    "colname = ' total(MB/s)'\n",
    "time_col = 'Time Elapsed (s)'\n",
    "\n",
    "# === Benchmark groups ===\n",
    "altis_base = '/Users/zhongzheng/Desktop/power/GPGPU/data/altis_power_res/no_power_shift/mem_throughput'\n",
    "altis_benchmarks = [\n",
    "    \"bfs\", \"gemm\", \"pathfinder\", \"sort\", \"cfd\", \"cfd_double\", \"fdtd2d\",\n",
    "    \"kmeans\", \"lavamd\", \"nw\", \"particlefilter_float\", \"raytracing\", \"where\"\n",
    "]\n",
    "\n",
    "ecp_base = '/Users/zhongzheng/Desktop/power/GPGPU/data/ecp_power_res/no_power_shift/mem_throughput'\n",
    "ecp_benchmarks = [\n",
    "    'Laghos', 'miniGAN', 'sw4lite', 'UNet', 'Resnet50', 'bert_large', 'lammps', 'gromacs'\n",
    "]\n",
    "\n",
    "benchmark_sets = [\n",
    "    (\"altis\", altis_base, altis_benchmarks),\n",
    "    (\"ecp\", ecp_base, ecp_benchmarks)\n",
    "]\n",
    "\n",
    "# === Fuzzy Jaccard with ±tolerance index ===\n",
    "def fuzzy_jaccard(burst_a, burst_b, tolerance=1):\n",
    "    a_idx = np.where(burst_a == 1)[0]\n",
    "    b_idx = np.where(burst_b == 1)[0]\n",
    "\n",
    "    matched_a = set()\n",
    "    matched_b = set()\n",
    "\n",
    "    for ai in a_idx:\n",
    "        # Find all b indices within ±tolerance of ai\n",
    "        nearby_b = b_idx[np.abs(b_idx - ai) <= tolerance]\n",
    "        if len(nearby_b) > 0:\n",
    "            matched_a.add(ai)\n",
    "            matched_b.update(nearby_b)\n",
    "\n",
    "    intersection = len(matched_a)\n",
    "    union = len(set(a_idx).union(set(b_idx)))\n",
    "\n",
    "    if union == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "# === Main loop ===\n",
    "results = []\n",
    "\n",
    "for label, base_dir, benchmarks in benchmark_sets:\n",
    "    for app in benchmarks:\n",
    "        try:\n",
    "            # Load CSVs\n",
    "            path_max = os.path.join(base_dir, 'max_uncore', f'{app}.csv')\n",
    "            path_mag = os.path.join(base_dir, 'dynamic_uncore', f'{app}.csv')\n",
    "\n",
    "            df_max = pd.read_csv(path_max)\n",
    "            df_mag = pd.read_csv(path_mag)\n",
    "\n",
    "            # Optional filtering\n",
    "            if app == 'bert_large':\n",
    "                df_max = df_max[df_max[time_col].between(220, 300)]\n",
    "                df_mag = df_mag[df_mag[time_col].between(220, 300)]\n",
    "            elif app == 'Resnet50':\n",
    "                df_max = df_max[df_max[time_col].between(60, 300)]\n",
    "                df_mag = df_mag[df_mag[time_col].between(60, 300)]\n",
    "\n",
    "            # Parse throughput column\n",
    "            T_max = pd.to_numeric(df_max[colname].astype(str).str.strip(), errors='coerce').dropna().values\n",
    "            T_mag = pd.to_numeric(df_mag[colname].astype(str).str.strip(), errors='coerce').dropna().values\n",
    "\n",
    "            # Align lengths\n",
    "            min_len = min(len(T_max), len(T_mag))\n",
    "            T_max = T_max[:min_len]\n",
    "            T_mag = T_mag[:min_len]\n",
    "\n",
    "            # Adaptive threshold based on 90% of T_max\n",
    "            adaptive_threshold = T_max.max() * 0.3\n",
    "\n",
    "            # Binary burst detection\n",
    "            burst_max = (T_max > adaptive_threshold).astype(int)\n",
    "            burst_mag = (T_mag > adaptive_threshold).astype(int)\n",
    "\n",
    "            # Fuzzy Jaccard (±1 time step tolerance)\n",
    "            jaccard = round(fuzzy_jaccard(burst_max, burst_mag, tolerance=1), 3)\n",
    "\n",
    "            results.append((label, app, round(adaptive_threshold, 1), jaccard))\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append((label, app, \"N/A\", f\"ERROR: {e}\"))\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"\\n=== Jaccard Burst Overlap Similarity (Fuzzy ±1s Tolerance) ===\")\n",
    "print(f\"{'Group':<6} {'App':<20} {'Threshold':<10} {'Jaccard'}\")\n",
    "for group, app, thresh, score in results:\n",
    "    print(f\"{group:<6} {app:<20} {thresh:<10} {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa675a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
